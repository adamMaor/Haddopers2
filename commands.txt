vagrant destroy -f
./start.sh


sudo chown -R vagrant $HADOOP_HOME


start-all.sh
start-dfs.sh
start-yarn.sh


#aliases

alias vd='vagrant destroy -f'
alias vs='./start.sh'
alias slave='vagrant ssh nodeA'
alias master='vagrant ssh nodeB'



hadoop jar \
../share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar \
org.apache.hadoop.yarn.applications.distributedshell.Client \
--jar ../share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.2.jar \
--shell_command date --num_containers 2 --master_memory 1024

#Hadoop cluster startup from apache.hadoop reference
[hdfs]$ $HADOOP_PREFIX/bin/hdfs namenode -format <cluster_name>
[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script hdfs start namenode
[hdfs]$ $HADOOP_PREFIX/sbin/hadoop-daemons.sh --config $HADOOP_CONF_DIR --script hdfs start datanode
[hdfs]$ $HADOOP_PREFIX/sbin/start-dfs.sh
[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start resourcemanager
[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemons.sh --config $HADOOP_CONF_DIR start nodemanager
[yarn]$ $HADOOP_YARN_HOME/sbin/yarn-daemon.sh --config $HADOOP_CONF_DIR start proxyserver
[yarn]$ $HADOOP_PREFIX/sbin/start-yarn.sh
[mapred]$ $HADOOP_PREFIX/sbin/mr-jobhistory-daemon.sh --config $HADOOP_CONF_DIR start historyserver
